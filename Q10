from pyspark.sql import SparkSession
from pyspark.sql.functions import sum

spark = SparkSession.builder.getOrCreate()

total_amount_df = purchases.groupBy("customer_id").agg(sum("amount").alias("total_amount"))

top_customers = total_amount_df.orderBy("total_amount", ascending=False).limit(5)

top_customers.show()
